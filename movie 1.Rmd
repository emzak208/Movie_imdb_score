---
title: "Regression Analysis of IMDB 5000 Movies Datasets"
output: html_notebook
---
Purpose:
By doing a regresson analysis, we want to know:
1) Among the 27 variables given, which of them are critical in telling the IMDB rating of a movie.
2) Is there any correlation between genre & IMDB raging,face number in poster & IMDB rating,director name & IMDB rating and duration & IMDB rating.
3) Predict the IMDB Score using our model

```{r}
m<- read.csv('movie_metadata.csv')
```
## Step 1: Data Collection 
This data set was found from Kaggle. The author scraped 5000+ movies from IMDB website using a Python library called "scrapy" and obtain all needed 28 variables for 5043 movies and 4906 posters (998MB), spanning across 100 years in 66 countries. There are 2399 unique director names, and thousands of actors/actresses. Below are the 28 variables:
"movie_title" "color" "num_critic_for_reviews" "movie_facebook_likes" "duration" "director_name" "director_facebook_likes" "actor_3_name" "actor_3_facebook_likes" "actor_2_name" "actor_2_facebook_likes" "actor_1_name" "actor_1_facebook_likes" "gross" "genres" "num_voted_users" "cast_total_facebook_likes" "facenumber_in_poster" "plot_keywords" "movie_imdb_link" "num_user_for_reviews" "language" "country" "content_rating" "budget" "title_year" "imdb_score" "aspect_ratio"

This dataset is a proof of concept. It can be used for experimental and learning purpose.For comprehensive movie analysis and accurate movie ratings prediction, 28 attributes from 5000 movies might not be enough. A decent dataset could contain hundreds of attributes from 50K or more movies, and requires tons of feature engineering.

## Step 2 : Data cleaning and exploration

Assign the first word of genres as the genre of each movie:(genres been split into words in Excel):
```{r}
# remove columns X-X.8
which(colnames(m)=='genres')
which(colnames(m)=='X.8')
m<-m[,-c(11:19)]
```

Only keep movie data for USA, bacause the "budget" variable was not all converted to US dollars, which might cause a problem in later analysis. If we want to convert all budgets into US dollarts, we have to take in to consideration for inflation as well. This might make the problem more complicated. Therefore, for pratice purpose, we decided to only study data for movies of USA. 
```{r}
movie.usa<-m[which(m[,'country']=='USA'),]
```
Double check:
```{r}
movie.usa$country
```

Remove 'language' since after removing all countries except for USA, there is only 4 languages aside from English, not meaningful for our prediction. 
```{r}
summary(movie.usa$language)
movie.usa<-movie.usa[, -which(names(movie.usa)=='language')]
```

Remove 'movie_imdb_link' column since it's not useful for our analysis and store the rest od the data as 'movie'.
```{r}
movie.df= data.frame(movie.usa)
mm<-movie.df[, -which(names(movie.df)=='movie_imdb_link')] 
```


```{r}
str(mm)
```

Check for missing values:
```{r}
library(Amelia)
missmap(mm, main = "Missing values vs observed")
sapply(mm,function(x) sum(is.na(x))) # number of missing values for each variable 
```
We noticed that there are many missing values for budget,aspect ratio and gross.

Omit missing values:
```{r}
movie<-na.omit(mm)
sapply(movie,function(x) sum(is.na(x))) # double check for missing values
```


```{r}
library(psych)
library(car)
library(RColorBrewer) 
library(corrplot)
library(ggplot2)
```

Explore title_year predictor:
```{r}
range(movie$title_year) # check movie title year
sum(with(movie,title_year=='2009')) # 145
sum(with(movie,title_year=='2014')) # 121
```
Visualization of title Year vs. Score:
```{r}
scatterplot(x=movie$title_year,y=movie$imdb_score)
```
There are many outliers for title year. The mojority of data points are around the year of 2000 and later,which make sense that this is less movies in the early years. Also, an intering notice is that movies from early years tend to have higher scores. 



Visualization of IMDB Score:
```{r}
max(movie$imdb_score) # 9.4
ggplot(movie, aes(x = imdb_score)) +
        geom_histogram(aes(fill = ..count..), binwidth =0.5) +
        scale_x_continuous(name = "IMDB Score",
                           breaks = seq(0,10),
                           limits=c(1, 10)) +
        ggtitle("Histogram of Movie IMDB Score") +
        scale_fill_gradient("Count", low = "blue", high = "red")
```
```{r}
sum(with(movie,imdb_score>=8))
# 148 movies with IMDB score greater or equal to 8.
```
IMDB score looks normal.The highest score is 9.4 out of scale 10. And we can consider movies with a score greater or equal to 8 a great movie from many perspectives.


Exploring correlation :
```{r}
pairs.panels(movie[c('director_name','duration','facenumber_in_poster','imdb_score','genres')])
```
from the plot, only duration and IMBD score has a high correlation.
face number in posters has a negative correaltion with IMBD score.
genre has little correlatin with score
Interesting, director name has no correlation with IMDB score


```{r}
pairs.panels(movie[c('color','actor_1_name','title_year','imdb_score','aspect_ratio','gross')])
```
Color and title year has highly positive correlation.
Color and aspect ratia,gross has smaller positive correlations.
Actor 1 namem has very small positive correlation with gross, meaning who plays the movies does not have impact on the gross.
Title year and aspect ratio and color are highly positively correlated.
IMDB score has very small positive correlation with actor 1 name ,which means who was the actor 1 does not make the movie has a higher score.
Interestingly, IMDB score has a negative correlation with title year,which means the old movies seems to have a higher score. the result agrees with out pbservation from the scatter plot. 
IMDB and aspect ratio has  small positive correlation.
IMDB has a strong positive correlation with gross.


Corplot for all numerical variables:
```{r}
nums<- sapply(movie,is.numeric) # select numeric columns
movie.num<- movie[,nums]
corrplot(cor(movie.num),method='ellipse') 
```
Note: corrplot cannot use data.frame, use cor() to change it to matrix.

From the correlation plot, we can tell that:
Face number in poster has negative correlation with all other predictors.
Cast total facebook likes and actor 1 facebook likes has a stronger positive correlation.
budget and gross have strong correaltion which is not surprising.
Interestingly, IMDB scores has strong positive corrlation with number of critics for review, which means the more the critics review, the higher the score.Duration and number of voted users also have strong positive correlation with IMDB scores. 


Find the pairs of correlations
```{r}
corr.test(movie.num,y=NULL,use='pairwise',method='pearson',adjust='holm',alpha=0.05) # x must be numeric
```
```{r}
# Boxplots for significant categorical predictors
Boxplot(movie$imdb_score,movie$color)

```
Black and white movies seems to have a hither meadian rate, and overall a little higher scores. 
Colors movies have many outliers. 

Boxplot for genre:
```{r}
fill <- "Blue"
line <- "Red"
ggplot(movie, aes(x = genres, y =imdb_score)) +
        geom_boxplot(fill = fill, colour = line) +
        scale_y_continuous(name = "IMDB Score",
                           breaks = seq(0, 11, 0.5),
                           limits=c(0, 11)) +
        scale_x_discrete(name = "Genres") +
        ggtitle("Boxplot of IMDB Score and Genres")
```
From the boxplot of genres, "Documentation" has the highest median score.And Trill movies has the lowest median. But it is also because there is 1 observation for thrill movies in our data set. 

```{r}
summary(movie$genres)
```

# Boxplots for "title year':
```{r}
library(ggplot2)
fill <- "Blue"
line <- "Red"
ggplot(movie, aes(x = as.factor(title_year), y =imdb_score)) +
        geom_boxplot(fill = fill, colour = line) +
        scale_y_continuous(name = "IMDB Score",
                           breaks = seq(1.5, 10, 0.5),
                           limits=c(1.5, 10)) +
        scale_x_discrete(name = "title_year") +
        ggtitle("Boxplot of IMDB Score and Genres")
```
The median of imdb score of all years seem different. So let's try to treat title_year as categorical.


```{r}
# Scatter plot matrix for correlation significant numerical variables
scatterplotMatrix(~movie$imdb_score+movie$num_voted_users+movie$num_critic_for_reviews+movie$num_user_for_reviews+movie$duration+movie$facenumber_in_poster+movie$gross+movie$movie_facebook_likes+movie$director_facebook_likes+movie$cast_total_facebook_likes+movie$budget)
```


## Step 3: fitting regression model 
```{r}
movie.sig<-movie[,c('imdb_score','num_voted_users','num_critic_for_reviews','num_user_for_reviews','duration','facenumber_in_poster','gross','movie_facebook_likes','director_facebook_likes','cast_total_facebook_likes','budget','title_year','genres')]
```

Step function to check AIC criteria: 
```{r}
null=lm(movie.sig$imdb_score~1) # set null model
summary(null)
```

1. Full model is linear additive model
```{r}
full1=lm(movie.sig$imdb_score~movie.sig$num_voted_users+movie.sig$num_critic_for_reviews+movie.sig$num_user_for_reviews+movie.sig$duration+movie.sig$facenumber_in_poster+movie.sig$gross+movie.sig$movie_facebook_likes+movie.sig$director_facebook_likes+movie.sig$cast_total_facebook_likes+movie.sig$budget+movie.sig$title_year+factor(movie.sig$genres))
summary(full1)
```

```{r}
step(null,scope = list(lower=null,upper=full1),direction = 'forward')
```


2. full model is polynomial regresison model with interaction terms:
```{r}
full2=lm(movie.sig$imdb_score~poly(movie.sig$num_voted_users,2)+poly(movie.sig$num_critic_for_reviews,2)+poly(movie.sig$num_user_for_reviews,2)+poly(movie.sig$duration,2)+movie.sig$facenumber_in_poster+poly(movie.sig$gross,2)+poly(movie.sig$movie_facebook_likes,2)+movie.sig$director_facebook_likes+movie.sig$cast_total_facebook_likes+movie.sig$budget+movie.sig$title_year+movie.sig$genres+movie.sig$facenumber_in_poster*movie.sig$num_critic_for_reviews+movie.sig$num_user_for_reviews*movie.sig$num_voted_users+movie.sig$num_voted_users*movie.sig$gross+movie.sig$gross*movie.sig$budget)
summary(full2)
```

```{r}
step(null,scope=list(lower=null,upper=full2),direction='forward')
```

3. full3: additive model with interaction
```{r}
full3=
lm(movie.sig$imdb_score ~movie.sig$num_voted_users+movie.sig$num_critic_for_reviews+movie.sig$num_user_for_reviews+movie.sig$duration+movie.sig$facenumber_in_poster+movie.sig$gross+movie.sig$movie_facebook_likes+movie.sig$director_facebook_likes+movie.sig$cast_total_facebook_likes+movie.sig$budget+movie.sig$title_year+factor(movie.sig$genres)+movie.sig$duration*movie.sig$num_voted_users+movie.sig$num_voted_users*movie.sig$num_user_for_reviews+movie.sig$gross*movie.sig$budget,data=movie.sig)
summary(full3)
```

```{r}
step(null,scope=list(lower=null,upper=full3),direction='forward')
```

For convinience to interpret the result, I will start with Full3(additive mode with interactiin terms). After checking residual, then decide should we add higher order terms.

Split data into Test and Train:
```{r}
set.seed(234) # 234(0.4456)
indx = sample(1:nrow(movie.sig), as.integer(0.9*nrow(movie.sig)))
indx # ramdomize rows, save 90% of data into index

movie_train = movie.sig[indx,]
movie_test = movie.sig[-indx,]
```

```{r}
# lm.fit 1: linear model with interaction term dropping insig predictors.
# insig terms: director facebooklike','movie fb like' and 'cast total fb likes' from summary(full3)
# Note: nothing to do with step function we choose for full3.
lm.fit1<-lm(movie_train$imdb_score~movie_train$num_voted_users+movie_train$num_critic_for_reviews+movie_train$num_user_for_reviews+movie_train$duration+movie_train$facenumber_in_poster+movie_train$gross+movie_train$budget+movie_train$title_year+factor(movie_train$genres)+movie_train$duration*movie_train$num_voted_users+movie_train$num_voted_users*movie_train$num_user_for_reviews+movie_train$gross*movie_train$budget)
summary(lm.fit1)
```
The P-value is very samll.All terms are significant but face number in posters and gross are less significant than other variables.Adjusted R^2 is 0.4718, which means 47.18% of the variability can be explained by this model. 


Do Lack of fit test to see if removing the predictors improve model performance:
```{r}
#lm.full: full linear model with interaction terms on train dataset.
lm.full<-lm(movie_train$imdb_score~movie_train$num_voted_users+movie_train$num_critic_for_reviews+movie_train$num_user_for_reviews+movie_train$duration+movie_train$facenumber_in_poster+movie_train$gross+movie_train$movie_facebook_likes+movie_train$director_facebook_likes+movie_train$cast_total_facebook_likes+movie_train$budget+movie_train$title_year+factor(movie_train$genres)+movie_train$duration*movie_train$num_voted_users+movie_train$num_voted_users*movie_train$num_user_for_reviews+movie_train$gross*movie_train$budget)
```

```{r}
anova(lm.full,lm.fit1) # H0: reduced model fits===lack of fit=0
```
The P-value of the partial F-test is 0.1331, which means dropping 'director facebooklike','movie fb like' and 'cast total fb likes' did improve model performance.

Diagnostics:
```{r}
plot(lm.fit1)
# residual vs fitted indicates might be higher order term. Normal plot not good.
```

```{r}
library(car)
residualPlots(lm.fit1)
```
Mots of the residual vs predictor plots have a general trend of curviture, which indicates the current model does not fit. Higher order terms should be included.

Fit model with higer order terms:
```{r}
# lm.fit2: model based on lm.fit1 adding higer order for all variables except for 'face number in poster' and 'title-year'.
lm.fit2<-lm(movie_train$imdb_score~poly(movie_train$num_voted_users,2)+poly(movie_train$num_critic_for_reviews,2)+poly(movie_train$num_user_for_reviews,2)+poly(movie_train$duration,2)+movie_train$facenumber_in_poster+poly(movie_train$gross,2)+poly(movie_train$budget,2)+movie_train$title_year+factor(movie_train$genres)+movie_train$duration*movie_train$num_voted_users+movie_train$num_voted_users*movie_train$num_user_for_reviews+movie_train$gross*movie_train$budget)
summary(lm.fit2)
```
The second order term for 'num_user_for_review' and 'gross' is sig but close to not sig, can be droped.
The interaction for 'gross' and 'budget' is not very significant, could be droped.

```{r}
anova(lm.fit1, lm.fit2)
```


```{r}
# lm.fit3: based on lm.fit2 dropping second order term for 'num_user_for_review','gross' and budget*gross
lm.fit3<-lm(movie_train$imdb_score~poly(movie_train$num_voted_users,2)+poly(movie_train$num_critic_for_reviews,2)+movie_train$num_user_for_reviews+poly(movie_train$duration,2)+movie_train$facenumber_in_poster+movie_train$gross+poly(movie_train$budget,2)+movie_train$title_year+factor(movie_train$genres)+movie_train$duration*movie_train$num_voted_users+movie_train$num_voted_users*movie_train$num_user_for_reviews)
summary(lm.fit3)
```
Gross not sig,drop



```{r}
anova(lm.fit2,lm.fit3) 
```
P-value for lack of fit test is : 0.01378. Drop the three terms not improving model 
Meaning lm.fit3 does not fit.


Diagnostics for lm.fit2:
```{r}
plot(lm.fit2)
```

```{r}
library(car)
residualPlots(lm.fit2)
```
The plot is way better than lm.fit2. All the residuals vs predictors are strainght lines except for title year. So, let't try to add second order for title year.


```{r}
# lm.fit4: based on lm.fit2 addting second order for title year.
lm.fit4<-lm(movie_train$imdb_score~poly(movie_train$num_voted_users,2)+poly(movie_train$num_critic_for_reviews,2)+poly(movie_train$num_user_for_reviews,2)+poly(movie_train$duration,2)+movie_train$facenumber_in_poster+poly(movie_train$gross,2)+poly(movie_train$budget,2)+poly(movie_train$title_year,2)+factor(movie_train$genres)+movie_train$duration*movie_train$num_voted_users+movie_train$num_voted_users*movie_train$num_user_for_reviews+movie_train$gross*movie_train$budget)
summary(lm.fit4)

```

```{r}
anova(lm.fit2,lm.fit4)
```
P value is so small, reject null, meaning adding second order term for title year did not improve model.

```{r}
AIC(lm.fit2)
AIC(lm.fit4)
```


Marginal Model plot:
```{r}
library(car)
marginalModelPlots(lm.fit2)
```
The plots of the response versus the individual predictors display the conditional distribution of the response given each predictor, ignoring the other predictors.
From our plots, our model is really good.since the marginal relationship between the response and the predictor are overlapping. 

Check for residual ourliers:
```{r}
library(car)
qqPlot(lm.fit2$residuals,id.n = 10)
```

```{r}
library(car)
outlierTest(lm.fit2) # H0: residual is not an outlier
```
All of the 10 residuals have significant p-values, therefore, we can drop them.

Before we drop, let's do some digsnostics to double check which to drop.
```{r}
library(car)
influencePlot(lm.fit2, id.n=10)
```
From the influcence plot, we decided to drop observations:
509,425,17,1443,2559,1222,1200,165,1418,139

```{r}
# lm.fit5: model based on lm.fit4 removing 10 outliers.
movie_train<-movie_train[-c(509,425,17,1443,2559,1222,1200,165,1418,139),]

lm.fit5<-lm(movie_train$imdb_score~poly(movie_train$num_voted_users,2)+poly(movie_train$num_critic_for_reviews,2)+poly(movie_train$num_user_for_reviews,2)+poly(movie_train$duration,2)+movie_train$facenumber_in_poster+poly(movie_train$gross,2)+poly(movie_train$budget,2)+movie_train$title_year+factor(movie_train$genres)+movie_train$duration*movie_train$num_voted_users+movie_train$num_voted_users*movie_train$num_user_for_reviews+movie_train$gross*movie_train$budget)
summary(lm.fit5)
```

```{r}
compareCoefs(lm.fit2, lm.fit5)
```
Removing outliers did not change the result too much.



Diagnostics for lm.fit5:
```{r}
library(car)
residualPlots(lm.fit5)
```
Looks good except for residuals vs fitted values show some curviture.

```{r}
plot(lm.fit5)
```

Now,let's look at model assumption for both lm.fit2 and lm.fit5:
```{r}
# normality
shapiro.test(lm.fit2$residuals)
shapiro.test(lm.fit5$residuals)
```
Both models failed the normality assumption. I think this is due to the many outliers in the data set. 

```{r}
# equal variance : H0: variance is not constant
ncvTest(lm.fit2)
ncvTest(lm.fit5)
```
Both models passed the equal variance assumption. 


This is just to explore more interesting facts
Plots for data with fitted regression line:
```{r}
library(ggplot2)
ggplot(data=movie_train,aes(x=duration,y=imdb_score,colour=factor(genres)))+stat_smooth(method=lm,fullrange = FALSE)+geom_point()
```


```{r}
library(ggplot2)
ggplot(data=movie_train,aes(x=num_voted_users,y=imdb_score,colour=factor(genres)))+stat_smooth(method=lm,fullrange = FALSE)+geom_point()
```

```{r}
library(ggplot2)
ggplot(data=movie_train,aes(x=facenumber_in_poster,y=imdb_score,colour=factor(genres)))+stat_smooth(method=lm,fullrange = FALSE)+geom_point()
```


```{r}
library(ggplot2)
ggplot(data=movie_train,aes(x=gross,y=imdb_score,colour=factor(genres)))+stat_smooth(method=lm,fullrange = FALSE)+geom_point()
```

```{r}
library(ggplot2)
ggplot(data=movie_train,aes(x=budget,y=imdb_score,colour=factor(genres)))+stat_smooth(method=lm,fullrange = FALSE)+geom_point()
```


##Step 4: Making predictions on the test dataset
Rewriting model lm.fit5 in another notation:
# Note, if write in lm(train$score~train$x1+train$x2....), it will create the same number of values with the train data set when predict().
```{r}
# lm.fit6 =lm.fit 2 using difference writing
lm.fit6<-lm(imdb_score~poly(num_voted_users,2)+poly(num_critic_for_reviews,2)+poly(num_user_for_reviews,2)+poly(duration,2)+facenumber_in_poster+poly(gross,2)+poly(budget,2)+title_year+factor(genres)+duration*num_voted_users+num_voted_users*num_user_for_reviews+gross*budget,data=data.frame(movie_train))
summary(lm.fit6)
```


```{r}
pr<-predict.lm(lm.fit6,newdata = data.frame(movie_test),interval = 'confidence')
pr[1:20,]
```

Check Accuracy:
Mean Absolute Error: how far, on average, prediction is from the true value. 
```{r}
MAE <- function(actual, predicted) {
mean(abs(actual - predicted))
}
MAE(pr, movie_test$imdb_score)
```
57% of the imdb scores in test data set have been  correctly predicted by our model.


Checking the impact significance of predictors on IMDB score.
```{r}
# stantdardized regression coefficients
library(QuantPsyc)
lm.beta(lm.fit6)
```

Conclusion:
The most important factor that affects movie rating is the duration. The longer the movie is, the higher the rating will be.
num_critic_for_reviews is also an important predictor. 
Budget is important, although there is no strong correlation between budget and movie rating.
The number of faces in movie poster has a non-neglectable effect to the movie rating.









